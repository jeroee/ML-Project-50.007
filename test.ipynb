{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "EN_train = 'EN/train'\n",
    "SG_train = 'SG/train'\n",
    "CN_train = 'CN/train'\n",
    "EN_test = 'EN/dev.in'\n",
    "SG_test = 'SG/dev.in'\n",
    "CN_test = 'CN/dev.in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "181628\n27225\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    word\n",
       "0    HBO\n",
       "1    has\n",
       "2  close\n",
       "3     to\n",
       "4     24"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>has</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "source": [
    "def load_train(training_file):\n",
    "    df = pd.read_csv(training_file, sep=' ', header = None, error_bad_lines=False)\n",
    "    df.columns=['word','state']\n",
    "    return df\n",
    "\n",
    "def load_test(test_file):\n",
    "    ls = []\n",
    "    f = open(test_file,encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        ls.append(line.strip('\\n'))\n",
    "    df_test = pd.DataFrame(ls)\n",
    "    df_test.columns=['word']\n",
    "    return df_test\n",
    "        \n",
    "# df_test = load_test(EN_test)\n",
    "# print(len(df_test))\n",
    "df_train = load_train(EN_train)\n",
    "print(len(df_train))\n",
    "df_train.head(5)\n",
    "\n",
    "df_test = load_test(EN_test)\n",
    "print(len(df_test))\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time elapsed 0.8319985866546631 seconds\n"
     ]
    }
   ],
   "source": [
    "def createMatrix(df):\n",
    "    start = time.time()\n",
    "    columns = df.word.unique().tolist()\n",
    "    index = df.state.unique().tolist()\n",
    "    new_df = pd.DataFrame(columns=columns, index=index)\n",
    "    print(f'time elapsed {time.time()-start} seconds')\n",
    "    return new_df\n",
    "empty_matrix = createMatrix(df_train)    \n",
    "# emission_matrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21\n18212\n"
     ]
    }
   ],
   "source": [
    "print(len(empty_matrix))\n",
    "print(len(empty_matrix.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "25051it [00:09, 2636.12it/s]\n",
      "time elapsed 11.418999433517456\n"
     ]
    }
   ],
   "source": [
    "def emissionMatrix_special(df, emission_matrix):\n",
    "    k=0.5\n",
    "    start = time.time()\n",
    "    df_denominator = df.groupby('state').count()   # getting counts of states\n",
    "    df_counts = df.groupby(['state','word']).size().reset_index()   # getting counts of every word in each state\n",
    "    df_merged = df_counts.merge(df_denominator, left_on=['state'], right_on='state')  # merge \n",
    "    df_merged = df_merged.rename(columns={\"word_x\": \"word\",0:\"word_count\", \"word_y\": \"state_count\"})\n",
    "    df_merged['Probability'] = df_merged.word_count/(df_merged.state_count+k)    # get emission probability (count of word in that state/ state count)\n",
    "    for index, row in tqdm(df_merged.iterrows()):  # for every known probabilty\n",
    "        emission_matrix.loc[row['state'],row['word']] = row['Probability']   # append into the emission matrix\n",
    "    for i in df_train.state.unique().tolist():\n",
    "        emission_matrix.loc[i,'#UNK#'] = float(k/df_denominator.loc[i]+k)\n",
    "    emission_matrix = emission_matrix.fillna(0)   # fill those null cells with zero\n",
    "    print(f'time elapsed {time.time()-start}')\n",
    "    return emission_matrix\n",
    "\n",
    "emission_matrix = emissionMatrix_special(df_train, empty_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time elapsed 0.00800633430480957\n"
     ]
    }
   ],
   "source": [
    "def argmax(df):\n",
    "    start = time.time()\n",
    "    tags={}\n",
    "    for col in df.columns:\n",
    "        tags[col]=df.index[df[col].argmax()]\n",
    "    return tags\n",
    "        \n",
    "tags = argmax(emission_matrix)\n",
    "\n",
    "def tag_system(tag_dict, test_df):\n",
    "    start = time.time()\n",
    "    test_ls = test_df['word'].tolist()\n",
    "    tag_states=[]\n",
    "    for i in test_ls:\n",
    "        if i in tag_dict.keys():\n",
    "            tag_states.append(tag_dict[i])\n",
    "        elif i==\"\":   # for blank lines, set state to be blank\n",
    "            tag_states.append(\"\")\n",
    "        elif i not in tag_dict.keys():\n",
    "            tag_states.append(tag_dict['#UNK#'])\n",
    "\n",
    "    test_df['states']=tag_states\n",
    "    print(f'time elapsed {time.time()-start}')\n",
    "    return test_df\n",
    "output = tag_system(tags,df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           word   states\n",
       "0           HBO     B-NP\n",
       "1           has     B-VP\n",
       "2         close   B-ADJP\n",
       "3            to     B-PP\n",
       "4            24     I-NP\n",
       "5       million     I-NP\n",
       "6   subscribers     I-NP\n",
       "7            to     B-PP\n",
       "8           its     B-NP\n",
       "9           HBO     B-NP\n",
       "10          and    I-UCP\n",
       "11      Cinemax    B-UCP\n",
       "12     networks     I-NP\n",
       "13            ,        O\n",
       "14        while   B-SBAR\n",
       "15     Showtime     B-NP\n",
       "16          and    I-UCP\n",
       "17          its     B-NP\n",
       "18       sister     I-NP\n",
       "19      service     I-NP\n",
       "20            ,        O\n",
       "21          The     B-NP\n",
       "22        Movie    B-UCP\n",
       "23      Channel     I-NP\n",
       "24            ,        O\n",
       "25         have     I-VP\n",
       "26         only  I-CONJP\n",
       "27        about     B-PP\n",
       "28           10   I-ADVP\n",
       "29      million     I-NP\n",
       "30            ,        O\n",
       "31    according     B-PP\n",
       "32           to     B-PP\n",
       "33         Paul     B-NP\n",
       "34        Kagan    B-UCP\n",
       "35   Associates     I-NP\n",
       "36            ,        O\n",
       "37            a    B-LST\n",
       "38       Carmel    B-UCP\n",
       "39            ,        O\n",
       "40       Calif.     B-NP\n",
       "41            ,        O\n",
       "42     research     I-NP\n",
       "43         firm     I-NP\n",
       "44            .        O\n",
       "45                      \n",
       "46   WASHINGTON    B-UCP\n",
       "47         LIES    B-UCP\n",
       "48          LOW    B-UCP\n",
       "49        after   B-SBAR"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>states</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBO</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>has</td>\n      <td>B-VP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>close</td>\n      <td>B-ADJP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n      <td>B-PP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>million</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>subscribers</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>to</td>\n      <td>B-PP</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>its</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HBO</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>and</td>\n      <td>I-UCP</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Cinemax</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>networks</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>while</td>\n      <td>B-SBAR</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Showtime</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>and</td>\n      <td>I-UCP</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>its</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>sister</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>service</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>The</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Movie</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Channel</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>have</td>\n      <td>I-VP</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>only</td>\n      <td>I-CONJP</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>about</td>\n      <td>B-PP</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10</td>\n      <td>I-ADVP</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>million</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>according</td>\n      <td>B-PP</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>to</td>\n      <td>B-PP</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Paul</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Kagan</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Associates</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>a</td>\n      <td>B-LST</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Carmel</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Calif.</td>\n      <td>B-NP</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>research</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>firm</td>\n      <td>I-NP</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>WASHINGTON</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LIES</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LOW</td>\n      <td>B-UCP</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>after</td>\n      <td>B-SBAR</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 249
    }
   ],
   "source": [
    "output.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_trans(training_file):\n",
    "    f = open(training_file)\n",
    "    ls_state = ['START']\n",
    "    for line in f:\n",
    "        item = line.strip('\\n').split(' ')\n",
    "        if len(item) == 2:\n",
    "            ls_state.append(item[1])\n",
    "        elif len(item) < 2:\n",
    "            ls_state.append('STOP')\n",
    "            ls_state.append('START')\n",
    "    ls_state.pop(-1)\n",
    "    return ls_state\n",
    "\n",
    "def relation_matrix(temp):\n",
    "    count = Counter(temp)\n",
    "    list_key = list(count.keys())\n",
    "    rls_matrix = pd.DataFrame(columns=list_key, index=list_key)\n",
    "    for (x, y), c in Counter(zip(temp, temp[1:])).items():\n",
    "        rls_matrix.loc[[x], [y]] = c/count[x]\n",
    "    rls_matrix = rls_matrix.fillna(value=0)\n",
    "    rls_matrix = rls_matrix.drop(columns='START')\n",
    "    rls_matrix = rls_matrix.drop(index='STOP')\n",
    "    return rls_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_ls = load_train_trans(EN_train)\n",
    "transition_matrix = relation_matrix(sequence_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            B-NP      I-NP      B-VP    B-ADVP    B-ADJP  I-ADJP      B-PP  \\\nSTART   0.648049  0.000000  0.018661  0.054287  0.003262     0.0  0.108704   \nB-NP    0.028898  0.684706  0.130303  0.009809  0.003213     0.0  0.058007   \nI-NP    0.047645  0.406679  0.134912  0.015332  0.004103     0.0  0.156509   \nB-VP    0.345217  0.000000  0.007229  0.031214  0.039209     0.0  0.098735   \nB-ADVP  0.210379  0.000000  0.215989  0.016269  0.016550     0.0  0.170547   \n\n               O      STOP    B-SBAR      I-VP    I-ADVP     B-PRT  I-PP  \\\nSTART   0.141850  0.000000  0.022576  0.000000  0.000000  0.000000   0.0   \nB-NP    0.080964  0.000233  0.003403  0.000000  0.000000  0.000359   0.0   \nI-NP    0.227327  0.000788  0.006375  0.000000  0.000000  0.000128   0.0   \nB-VP    0.067411  0.000055  0.025574  0.373912  0.000000  0.011171   0.0   \nB-ADVP  0.265358  0.000842  0.016269  0.000000  0.086957  0.000281   0.0   \n\n         B-CONJP  I-CONJP    B-INTJ  I-INTJ  I-SBAR     B-UCP  I-UCP     B-LST  \nSTART   0.000261      0.0  0.001305     0.0     0.0  0.000000    0.0  0.001044  \nB-NP    0.000085      0.0  0.000000     0.0     0.0  0.000021    0.0  0.000000  \nI-NP    0.000201      0.0  0.000000     0.0     0.0  0.000000    0.0  0.000000  \nB-VP    0.000164      0.0  0.000110     0.0     0.0  0.000000    0.0  0.000000  \nB-ADVP  0.000561      0.0  0.000000     0.0     0.0  0.000000    0.0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(transition_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission_matrix; transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = open('EN/dev.in', encoding=\"utf8\")\n",
    "ls=[]\n",
    "big_ls=[]\n",
    "for line in m:\n",
    "    item=line.strip('\\n')\n",
    "    if item=='':\n",
    "        big_ls.append(ls)\n",
    "        ls=[]\n",
    "    elif item!='':\n",
    "        ls.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-256-55b3d97f5f59>, line 7)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-256-55b3d97f5f59>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    layer_v= [a*b for a,b in zip(transition_matrix.,[all states --> i[j] #word in sentence])]\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Multiple=[] # will conrain\n",
    "for i in big_ls:  #for each sentene\n",
    "    Vertibri=[] # will contain weights for all layers within each document\n",
    "    forward_steps = len(i)+1 \n",
    "    for j in forward_steps: #for each layer\n",
    "        if j==0:  #start to first layer\n",
    "            layer_v= [a*b for a,b in zip(transition_matrix.,[all states --> i[j] #word in sentence])]\n",
    "            big_v.append(small_v)\n",
    "        elif j!=0 & j!=forward_steps: #not first or last step\n",
    "            small_v=[a*b*c for a,b,c in zip([small_v],[state-> state],[ state -> word])]\n",
    "            big_v.append(small_v)\n",
    "        else: #if last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def log(x, inf_replace=-1000):\n",
    "    out = np.log(x)\n",
    "    out[~np.isfinite(out)] = inf_replace\n",
    "    return out\n",
    "logged_emission = log(emission_matrix)\n",
    "logged_transition = log(transition_matrix)\n",
    "transition_np = logged_transition.drop(['START']).drop('STOP',axis=1).to_numpy()\n",
    "\n",
    "# test for one document\n",
    "tags = argmax(emission_matrix)   # vocab of words\n",
    "Vertibri = []\n",
    "document = big_ls[1]\n",
    "# print(document)\n",
    "forward_steps = len(document)+1\n",
    "for i in range(forward_steps):\n",
    "    if i == 0: # for from START to first layer\n",
    "        if document[i] in tags.keys():\n",
    "            layer = [t+e for t,e in zip(logged_transition.loc['START'].drop('STOP'), logged_emission[document[i]])]\n",
    "        elif document[i] not in tags.keys():\n",
    "            layer = [t+e for t,e in zip(logged_transition.loc['START'].drop('STOP'), logged_emission['#UNK#'])]\n",
    "        Vertibri.append(layer)\n",
    "        print(type(Vertibri[-1]))\n",
    "    elif i!=0 and i!=forward_steps-1: #not first or last step\n",
    "        prev_layer_prob = Vertibri[-1]*21\n",
    "        prev_layer_prob = np.array(prev_layer_prob).reshape(21,21).T\n",
    "        m = prev_layer_prob + transition_np\n",
    "        if document[i] in tags.keys():\n",
    "            emission_ls = logged_emission[document[i]].tolist()*21\n",
    "            emission_np = np.array(emission_ls).reshape(21,21)\n",
    "        elif document[i] not in tags.keys():\n",
    "            emission_ls = logged_emission['#UNK#'].tolist()*21\n",
    "            emission_np = np.array(emission_ls).reshape(21,21)\n",
    "        matrix = (m + emission_np)\n",
    "        layer = np.amax(matrix,0)\n",
    "        Vertibri.append(layer.tolist())\n",
    "    elif i == forward_steps-1:\n",
    "        prev_layer_prob = np.array(Vertibri[-1])\n",
    "        last = logged_transition.drop('START')['STOP'].tolist()\n",
    "        layer = prev_layer_prob+last\n",
    "        Vertibri.append(layer.tolist())\n",
    "\n",
    "state_order = []\n",
    "states = emission_matrix.index.tolist()\n",
    "# Vertibri.pop(0)\n",
    "for layer in Vertibri:\n",
    "    position = layer.index(max(layer))\n",
    "    state_order.append(states[position])\n",
    "# state_order = []\n",
    "# states = emission_matrix.index.tolist()\n",
    "# for layer in Vertibri:\n",
    "#     position = layer.index[max(layer)]\n",
    "#     # states = emission_matrix.index.tolist()\n",
    "#     state_order.append(states[position])\n",
    "# print(state_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n1\n6\n0\n1\n1\n2\n1\n1\n7\n7\n"
     ]
    }
   ],
   "source": [
    "print(Vertibri.pop(0))\n",
    "for layer in Vertibri:\n",
    "    print(layer.index(max(layer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-NP', 'I-NP', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "state_order = []\n",
    "states = emission_matrix.index.tolist()\n",
    "Vertibri.pop(0)\n",
    "for layer in Vertibri:\n",
    "    position = layer.index(max(layer))\n",
    "    # states = emission_matrix.index.tolist()\n",
    "    state_order.append(states[position])\n",
    "print(state_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12\n[-1063.760283498056, -69.02720322779868, -1064.5281240883241, -1063.9705784737496, -1065.0370092905787, -2055.63668852509, -1063.0002157498927, -56.503306164764126, -2057.767893020284, -1064.5400753324307, -3049.1346912043236, -2058.824627131409, -3048.8558640571327, -2061.22220022726, -3051.0874518682676, -2063.4495999446935, -3052.7124711870774, -3051.247847459574, -3052.7124711870774, -3052.7124711870774, -3052.7124711870774]\n7\n"
     ]
    }
   ],
   "source": [
    "print(len(Vertibri))\n",
    "print(Vertibri[11])\n",
    "print(Vertibri[11].index(max(Vertibri[11])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1055.39380749   -61.88077903 -1054.71560117 -1056.89027143\n -1057.56906696 -2049.28405913 -1054.56711094   -55.358485\n -1057.76789302 -1055.31396004 -2049.1346912  -1058.82462713\n -2048.85586406 -1061.22220023 -2051.08745187 -1063.44959994\n -2052.71247119 -2051.24784746 -2052.71247119 -2052.71247119\n -2052.71247119]\n[-8.366476004340175, -7.14642419728779, -9.812522917162035, -7.0803070441802864, -7.467942332285852, -6.352629396319567, -8.433104811033951, -1.1448211692559165, -1000.0, -9.226115291091546, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0]\n[-1063.7602835    -69.02720323 -1064.52812409 -1063.97057847\n -1065.03700929 -2055.63668853 -1063.00021575   -56.50330616\n -2057.76789302 -1064.54007533 -3049.1346912  -2058.82462713\n -3048.85586406 -2061.22220023 -3051.08745187 -2063.44959994\n -3052.71247119 -3051.24784746 -3052.71247119 -3052.71247119\n -3052.71247119]\n"
     ]
    }
   ],
   "source": [
    "prev_layer_prob = np.array(Vertibri[-2])\n",
    "print(prev_layer_prob)\n",
    "print(logged_transition.drop('START')['STOP'].tolist())\n",
    "\n",
    "print(prev_layer_prob + logged_transition.drop('START')['STOP'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['B-NP', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n['B-NP', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n"
     ]
    }
   ],
   "source": [
    "# transition_np = logged_transition.drop(['START']).drop('STOP',axis=1).to_numpy()\n",
    "# ls = Vertibri[-1]*21\n",
    "# prev_np = np.array(ls).reshape(21,21).T\n",
    "# print(prev_np)\n",
    "# print(Vertibri[-1].tolist()*21)\n",
    "# ls = logged_emission[document[3]].tolist()*21\n",
    "# emission_np = np.array(ls).reshape(21,21)\n",
    "# print(emission_np)\n",
    "\n",
    "print(logged_transition.drop('START').index.tolist())\n",
    "print(emission_matrix.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = argmax(emission_matrix)   # vocab of words\n",
    "# Vertibri = []\n",
    "# document = big_ls[1]\n",
    "# # print(document)\n",
    "# forward_steps = len(document)+1\n",
    "# for i in range(forward_steps):\n",
    "#     if i == 0: # for from START to first layer\n",
    "#         if document[i] in tags.keys():\n",
    "#             layer = [t*e for t,e in zip(transition_matrix.loc['START'].drop('STOP'), emission_matrix[document[i]])]\n",
    "#         elif document[i] not in tags.keys():\n",
    "#             layer = [t*e for t,e in zip(transition_matrix.loc['START'].drop('STOP'), emission_matrix['#UNK#'])]\n",
    "#         Vertibri.append(layer)\n",
    "#         break\n",
    "# print(Vertibri[0])\n",
    "# print(Vertibri[0].index(max(Vertibri[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "document = big_ls[1]\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prev prob matrix\n[[0.16666667 0.16666667 0.16666667]\n [0.         0.         0.        ]\n [0.0625     0.0625     0.0625    ]]\ntrans matrix\n[[0.16666667 0.         0.66666667]\n [0.25       0.         0.        ]\n [0.125      0.5        0.125     ]]\nem matrix\n[[0.16666667 0.25       0.125     ]\n [0.16666667 0.25       0.125     ]\n [0.16666667 0.25       0.125     ]]\nnext prob matrix\n[[0.00462963 0.         0.01388889]\n [0.         0.         0.        ]\n [0.00130208 0.0078125  0.00097656]]\n[0.00462963 0.0078125  0.01388889]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ls = [1/6]*3 + [0]*3 + [1/16]*3\n",
    "# print(ls)\n",
    "prev = np.array(ls).reshape(3,3)\n",
    "\n",
    "ls1 = [1/6,0,4/6,1/4,0,0,1/8,4/8,1/8]\n",
    "trans = np.array(ls1).reshape(3,3)\n",
    "\n",
    "ls2 = [1/6,1/4,1/8]*3\n",
    "print(len(ls))\n",
    "em = np.array(ls2).reshape(3,3)\n",
    "print('prev prob matrix')\n",
    "print(prev)\n",
    "print('trans matrix')\n",
    "print(trans)\n",
    "print('em matrix')\n",
    "print(em)\n",
    "\n",
    "output = np.multiply(prev,trans)\n",
    "output = np.multiply(output,em)\n",
    "print('next prob matrix')\n",
    "print(output)\n",
    "\n",
    "print(np.amax(output,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame\n----------\n     a   b   c\n0  21  72  67\n1  23  78  69\n2  32  74  56\n3  52  54  76\n\nNumpy Array\n----------\n [[21 72 67]\n [23 78 69]\n [32 74 56]\n [52 54 76]]\n(4, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "\t[[21, 72, 67],\n",
    "\t[23, 78, 69],\n",
    "\t[32, 74, 56],\n",
    "\t[52, 54, 76]],\n",
    "\tcolumns=['a', 'b', 'c'])\n",
    "\n",
    "print('DataFrame\\n----------\\n', df)\n",
    "\n",
    "#convert dataframe to numpy array\n",
    "arr = df.to_numpy()\n",
    "\n",
    "print('\\nNumpy Array\\n----------\\n', arr)\n",
    "\n",
    "print(arr.shape)"
   ]
  }
 ]
}