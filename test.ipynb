{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "EN_train = 'EN/train'\n",
    "SG_train = 'SG/train'\n",
    "CN_train = 'CN/train'\n",
    "EN_test = 'EN/dev.in'\n",
    "SG_test = 'SG/dev.in'\n",
    "CN_test = 'CN/dev.in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "7//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "181628\n27225\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    word\n",
       "0    HBO\n",
       "1    has\n",
       "2  close\n",
       "3     to\n",
       "4     24"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>has</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def load_train(training_file):\n",
    "    df = pd.read_csv(training_file, sep=' ', header = None, error_bad_lines=False)\n",
    "    df.columns=['word','state']\n",
    "    return df\n",
    "\n",
    "def load_test(test_file):\n",
    "    ls = []\n",
    "    f = open(test_file,encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        ls.append(line.strip('\\n'))\n",
    "    df_test = pd.DataFrame(ls)\n",
    "    df_test.columns=['word']\n",
    "    return df_test\n",
    "        \n",
    "# df_test = load_test(EN_test)\n",
    "# print(len(df_test))\n",
    "df_train = load_train(EN_train)\n",
    "print(len(df_train))\n",
    "df_train.head(5)\n",
    "\n",
    "df_test = load_test(EN_test)\n",
    "print(len(df_test))\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time elapsed 0.6731152534484863 seconds\n"
     ]
    }
   ],
   "source": [
    "def createMatrix(df):\n",
    "    start = time.time()\n",
    "    columns = df.word.unique().tolist()\n",
    "    index = df.state.unique().tolist()\n",
    "    new_df = pd.DataFrame(columns=columns, index=index)\n",
    "    print(f'time elapsed {time.time()-start} seconds')\n",
    "    return new_df\n",
    "empty_matrix = createMatrix(df_train)    \n",
    "# emission_matrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21\n18212\n"
     ]
    }
   ],
   "source": [
    "print(len(empty_matrix))\n",
    "print(len(empty_matrix.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "25051it [00:04, 6136.25it/s]\n",
      "time elapsed 5.726562976837158\n"
     ]
    }
   ],
   "source": [
    "def emissionMatrix_special(df, emission_matrix):\n",
    "    k=0.5\n",
    "    start = time.time()\n",
    "    df_denominator = df.groupby('state').count()   # getting counts of states\n",
    "    df_counts = df.groupby(['state','word']).size().reset_index()   # getting counts of every word in each state\n",
    "    df_merged = df_counts.merge(df_denominator, left_on=['state'], right_on='state')  # merge \n",
    "    df_merged = df_merged.rename(columns={\"word_x\": \"word\",0:\"word_count\", \"word_y\": \"state_count\"})\n",
    "    df_merged['Probability'] = df_merged.word_count/(df_merged.state_count+k)    # get emission probability (count of word in that state/ state count)\n",
    "    for index, row in tqdm(df_merged.iterrows()):  # for every known probabilty\n",
    "        emission_matrix.loc[row['state'],row['word']] = row['Probability']   # append into the emission matrix\n",
    "    for i in df_train.state.unique().tolist():\n",
    "        emission_matrix.loc[i,'#UNK#'] = float(k/df_denominator.loc[i]+k)\n",
    "    emission_matrix = emission_matrix.fillna(0)   # fill those null cells with zero\n",
    "    print(f'time elapsed {time.time()-start}')\n",
    "    return emission_matrix\n",
    "\n",
    "emission_matrix = emissionMatrix_special(df_train, empty_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time elapsed 0.01430201530456543\n"
     ]
    }
   ],
   "source": [
    "def argmax(df):\n",
    "    start = time.time()\n",
    "    tags={}\n",
    "    for col in df.columns:\n",
    "        tags[col]=[df[col].argmax()]\n",
    "    return tags\n",
    "        \n",
    "tags = argmax(emission_matrix)\n",
    "\n",
    "def tag_system(tag_dict, test_df):\n",
    "    start = time.time()\n",
    "    test_ls = test_df['word'].tolist()\n",
    "    tag_states=[]\n",
    "    for i in test_ls:\n",
    "        if i in tag_dict.keys():\n",
    "            tag_states.append(tag_dict[i])\n",
    "        elif i==\"\":   # for blank lines, set state to be blank\n",
    "            tag_states.append(\"\")\n",
    "        elif i not in tag_dict.keys():\n",
    "            tag_states.append(tag_dict['#UNK#'])\n",
    "\n",
    "    test_df['states']=tag_states\n",
    "    print(f'time elapsed {time.time()-start}')\n",
    "    return test_df\n",
    "output = tag_system(tags,df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           word states\n",
       "0           HBO    [0]\n",
       "1           has    [2]\n",
       "2         close    [4]\n",
       "3            to    [6]\n",
       "4            24    [1]\n",
       "5       million    [1]\n",
       "6   subscribers    [1]\n",
       "7            to    [6]\n",
       "8           its    [0]\n",
       "9           HBO    [0]\n",
       "10          and   [19]\n",
       "11      Cinemax   [18]\n",
       "12     networks    [1]\n",
       "13            ,    [7]\n",
       "14        while    [8]\n",
       "15     Showtime    [0]\n",
       "16          and   [19]\n",
       "17          its    [0]\n",
       "18       sister    [1]\n",
       "19      service    [1]\n",
       "20            ,    [7]\n",
       "21          The    [0]\n",
       "22        Movie   [18]\n",
       "23      Channel    [1]\n",
       "24            ,    [7]\n",
       "25         have    [9]\n",
       "26         only   [14]\n",
       "27        about    [6]\n",
       "28           10   [10]\n",
       "29      million    [1]\n",
       "30            ,    [7]\n",
       "31    according    [6]\n",
       "32           to    [6]\n",
       "33         Paul    [0]\n",
       "34        Kagan   [18]\n",
       "35   Associates    [1]\n",
       "36            ,    [7]\n",
       "37            a   [20]\n",
       "38       Carmel   [18]\n",
       "39            ,    [7]\n",
       "40       Calif.    [0]\n",
       "41            ,    [7]\n",
       "42     research    [1]\n",
       "43         firm    [1]\n",
       "44            .    [7]\n",
       "45                    \n",
       "46   WASHINGTON   [18]\n",
       "47         LIES   [18]\n",
       "48          LOW   [18]\n",
       "49        after    [8]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>states</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBO</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>has</td>\n      <td>[2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>close</td>\n      <td>[4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>million</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>subscribers</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>to</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>its</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HBO</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>and</td>\n      <td>[19]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Cinemax</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>networks</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>while</td>\n      <td>[8]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Showtime</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>and</td>\n      <td>[19]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>its</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>sister</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>service</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>The</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Movie</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Channel</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>have</td>\n      <td>[9]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>only</td>\n      <td>[14]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>about</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>million</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>according</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>to</td>\n      <td>[6]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Paul</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Kagan</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Associates</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>a</td>\n      <td>[20]</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Carmel</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Calif.</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>,</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>research</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>firm</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>.</td>\n      <td>[7]</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>WASHINGTON</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>LIES</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>LOW</td>\n      <td>[18]</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>after</td>\n      <td>[8]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "output.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_trans(training_file):\n",
    "    f = open(training_file)\n",
    "    ls_state = ['START']\n",
    "    for line in f:\n",
    "        item = line.strip('\\n').split(' ')\n",
    "        if len(item) == 2:\n",
    "            ls_state.append(item[1])\n",
    "        elif len(item) < 2:\n",
    "            ls_state.append('STOP')\n",
    "            ls_state.append('START')\n",
    "    ls_state.pop(-1)\n",
    "    return ls_state\n",
    "\n",
    "def relation_matrix(temp):\n",
    "    count = Counter(temp)\n",
    "    list_key = list(count.keys())\n",
    "    rls_matrix = pd.DataFrame(columns=list_key, index=list_key)\n",
    "    for (x, y), c in Counter(zip(temp, temp[1:])).items():\n",
    "        rls_matrix.loc[[x], [y]] = c/count[x]\n",
    "    rls_matrix = rls_matrix.fillna(value=0)\n",
    "    rls_matrix = rls_matrix.drop(columns='START')\n",
    "    rls_matrix = rls_matrix.drop(index='STOP')\n",
    "    return rls_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_ls = load_train_trans(EN_train)\n",
    "transition_matrix = relation_matrix(sequence_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            B-NP      I-NP      B-VP    B-ADVP    B-ADJP  I-ADJP      B-PP  \\\nSTART   0.648049  0.000000  0.018661  0.054287  0.003262     0.0  0.108704   \nB-NP    0.028898  0.684706  0.130303  0.009809  0.003213     0.0  0.058007   \nI-NP    0.047645  0.406679  0.134912  0.015332  0.004103     0.0  0.156509   \nB-VP    0.345217  0.000000  0.007229  0.031214  0.039209     0.0  0.098735   \nB-ADVP  0.210379  0.000000  0.215989  0.016269  0.016550     0.0  0.170547   \n\n               O      STOP    B-SBAR      I-VP    I-ADVP     B-PRT  I-PP  \\\nSTART   0.141850  0.000000  0.022576  0.000000  0.000000  0.000000   0.0   \nB-NP    0.080964  0.000233  0.003403  0.000000  0.000000  0.000359   0.0   \nI-NP    0.227327  0.000788  0.006375  0.000000  0.000000  0.000128   0.0   \nB-VP    0.067411  0.000055  0.025574  0.373912  0.000000  0.011171   0.0   \nB-ADVP  0.265358  0.000842  0.016269  0.000000  0.086957  0.000281   0.0   \n\n         B-CONJP  I-CONJP    B-INTJ  I-INTJ  I-SBAR     B-UCP  I-UCP     B-LST  \nSTART   0.000261      0.0  0.001305     0.0     0.0  0.000000    0.0  0.001044  \nB-NP    0.000085      0.0  0.000000     0.0     0.0  0.000021    0.0  0.000000  \nI-NP    0.000201      0.0  0.000000     0.0     0.0  0.000000    0.0  0.000000  \nB-VP    0.000164      0.0  0.000110     0.0     0.0  0.000000    0.0  0.000000  \nB-ADVP  0.000561      0.0  0.000000     0.0     0.0  0.000000    0.0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(transition_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission_matrix; transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = open('EN/dev.in', encoding=\"utf8\")\n",
    "ls=[]\n",
    "big_ls=[]\n",
    "for line in m:\n",
    "    item=line.strip('\\n')\n",
    "    if item=='':\n",
    "        big_ls.append(ls)\n",
    "        ls=[]\n",
    "    elif item!='':\n",
    "        ls.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def log(x, inf_replace=-1000):\n",
    "    out = np.log(x)\n",
    "    out[~np.isfinite(out)] = inf_replace\n",
    "    return out\n",
    "logged_emission = log(emission_matrix)\n",
    "logged_transition = log(transition_matrix)\n",
    "transition_np = logged_transition.drop(['START']).drop('STOP',axis=1).to_numpy()\n",
    "\n",
    "# test for one document\n",
    "tags = argmax(emission_matrix)   # vocab of words\n",
    "Vertibri = []\n",
    "document = big_ls[1]\n",
    "# print(document)\n",
    "forward_steps = len(document)+1\n",
    "for i in range(forward_steps):\n",
    "    if i == 0: # for from START to first layer\n",
    "        if document[i] in tags.keys():\n",
    "            layer = [t+e for t,e in zip(logged_transition.loc['START'].drop('STOP'), logged_emission[document[i]])]\n",
    "        elif document[i] not in tags.keys():\n",
    "            layer = [t+e for t,e in zip(logged_transition.loc['START'].drop('STOP'), logged_emission['#UNK#'])]\n",
    "        Vertibri.append(layer)\n",
    "        print(type(Vertibri[-1]))\n",
    "    elif i!=0 and i!=forward_steps-1: #not first or last step\n",
    "        prev_layer_prob = Vertibri[-1]*21\n",
    "        prev_layer_prob = np.array(prev_layer_prob).reshape(21,21).T\n",
    "        m = prev_layer_prob + transition_np\n",
    "        if document[i] in tags.keys():\n",
    "            emission_ls = logged_emission[document[i]].tolist()*21\n",
    "            emission_np = np.array(emission_ls).reshape(21,21)\n",
    "        elif document[i] not in tags.keys():\n",
    "            emission_ls = logged_emission['#UNK#'].tolist()*21\n",
    "            emission_np = np.array(emission_ls).reshape(21,21)\n",
    "        matrix = (m + emission_np)\n",
    "        layer = np.amax(matrix,0)\n",
    "        Vertibri.append(layer.tolist())\n",
    "    elif i == forward_steps-1:\n",
    "        prev_layer_prob = np.array(Vertibri[-1])\n",
    "        last = logged_transition.drop('START')['STOP'].tolist()\n",
    "        layer = prev_layer_prob+last\n",
    "        Vertibri.append(layer.tolist())\n",
    "\n",
    "state_order = []\n",
    "states = emission_matrix.index.tolist()\n",
    "# Vertibri.pop(0)\n",
    "for layer in Vertibri:\n",
    "    position = layer.index(max(layer))\n",
    "    state_order.append(states[position])\n",
    "# state_order = []\n",
    "# states = emission_matrix.index.tolist()\n",
    "# for layer in Vertibri:\n",
    "#     position = layer.index[max(layer)]\n",
    "#     # states = emission_matrix.index.tolist()\n",
    "#     state_order.append(states[position])\n",
    "# print(state_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1.1269149062712336, -1000.69312886269, -4.674406621256191, -3.606340285694397, -6.417859247451664, -1000.6914065360821, -2.91221798459123, -2.6460872352060765, -4.483487962690325, -1000.693048750519, -1000.690396147188, -1000.6910127080313, -1000.688672900165, -8.923956123652886, -1000.6776429940239, -7.296980590553456, -1000.5596157879354, -1000.6725278933573, -1000.0, -1000.4700036292458, -7.470853092860883]\n1\n1\n6\n0\n1\n1\n2\n1\n1\n7\n7\n"
     ]
    }
   ],
   "source": [
    "print(Vertibri.pop(0))\n",
    "for layer in Vertibri:\n",
    "    print(layer.index(max(layer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-NP', 'I-NP', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "state_order = []\n",
    "states = emission_matrix.index.tolist()\n",
    "Vertibri.pop(0)\n",
    "for layer in Vertibri:\n",
    "    position = layer.index(max(layer))\n",
    "    # states = emission_matrix.index.tolist()\n",
    "    state_order.append(states[position])\n",
    "print(state_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1055.39380749   -61.88077903 -1054.71560117 -1056.89027143\n -1057.56906696 -2049.28405913 -1054.56711094   -55.358485\n -1057.76789302 -1055.31396004 -2049.1346912  -1058.82462713\n -2048.85586406 -1061.22220023 -2051.08745187 -1063.44959994\n -2052.71247119 -2051.24784746 -2052.71247119 -2052.71247119\n -2052.71247119]\n[-8.366476004340175, -7.14642419728779, -9.812522917162035, -7.0803070441802864, -7.467942332285852, -6.352629396319567, -8.433104811033951, -1.1448211692559165, -1000.0, -9.226115291091546, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0, -1000.0]\n[-1063.7602835    -69.02720323 -1064.52812409 -1063.97057847\n -1065.03700929 -2055.63668853 -1063.00021575   -56.50330616\n -2057.76789302 -1064.54007533 -3049.1346912  -2058.82462713\n -3048.85586406 -2061.22220023 -3051.08745187 -2063.44959994\n -3052.71247119 -3051.24784746 -3052.71247119 -3052.71247119\n -3052.71247119]\n"
     ]
    }
   ],
   "source": [
    "prev_layer_prob = np.array(Vertibri[-2])\n",
    "print(prev_layer_prob)\n",
    "print(logged_transition.drop('START')['STOP'].tolist())\n",
    "\n",
    "print(prev_layer_prob + logged_transition.drop('START')['STOP'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['B-NP', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n['B-NP', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n"
     ]
    }
   ],
   "source": [
    "# transition_np = logged_transition.drop(['START']).drop('STOP',axis=1).to_numpy()\n",
    "# ls = Vertibri[-1]*21\n",
    "# prev_np = np.array(ls).reshape(21,21).T\n",
    "# print(prev_np)\n",
    "# print(Vertibri[-1].tolist()*21)\n",
    "# ls = logged_emission[document[3]].tolist()*21\n",
    "# emission_np = np.array(ls).reshape(21,21)\n",
    "# print(emission_np)\n",
    "\n",
    "print(logged_transition.drop('START').index.tolist())\n",
    "print(emission_matrix.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = argmax(emission_matrix)   # vocab of words\n",
    "# Vertibri = []\n",
    "# document = big_ls[1]\n",
    "# # print(document)\n",
    "# forward_steps = len(document)+1\n",
    "# for i in range(forward_steps):\n",
    "#     if i == 0: # for from START to first layer\n",
    "#         if document[i] in tags.keys():\n",
    "#             layer = [t*e for t,e in zip(transition_matrix.loc['START'].drop('STOP'), emission_matrix[document[i]])]\n",
    "#         elif document[i] not in tags.keys():\n",
    "#             layer = [t*e for t,e in zip(transition_matrix.loc['START'].drop('STOP'), emission_matrix['#UNK#'])]\n",
    "#         Vertibri.append(layer)\n",
    "#         break\n",
    "# print(Vertibri[0])\n",
    "# print(Vertibri[0].index(max(Vertibri[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "document = big_ls[1]\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\nprev prob matrix\n[[0.16666667 0.16666667 0.16666667]\n [0.         0.         0.        ]\n [0.0625     0.0625     0.0625    ]]\ntrans matrix\n[[0.16666667 0.         0.66666667]\n [0.25       0.         0.        ]\n [0.125      0.5        0.125     ]]\nem matrix\n[[0.16666667 0.25       0.125     ]\n [0.16666667 0.25       0.125     ]\n [0.16666667 0.25       0.125     ]]\nnext prob matrix\n[[0.00462963 0.         0.01388889]\n [0.         0.         0.        ]\n [0.00130208 0.0078125  0.00097656]]\n[0.00462963 0.0078125  0.01388889]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ls = [1/6]*3 + [0]*3 + [1/16]*3\n",
    "# print(ls)\n",
    "prev = np.array(ls).reshape(3,3)\n",
    "\n",
    "ls1 = [1/6,0,4/6,1/4,0,0,1/8,4/8,1/8]\n",
    "trans = np.array(ls1).reshape(3,3)\n",
    "\n",
    "ls2 = [1/6,1/4,1/8]*3\n",
    "print(len(ls))\n",
    "em = np.array(ls2).reshape(3,3)\n",
    "print('prev prob matrix')\n",
    "print(prev)\n",
    "print('trans matrix')\n",
    "print(trans)\n",
    "print('em matrix')\n",
    "print(em)\n",
    "\n",
    "output = np.multiply(prev,trans)\n",
    "output = np.multiply(output,em)\n",
    "print('next prob matrix')\n",
    "print(output)\n",
    "\n",
    "print(np.amax(output,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame\n----------\n     a   b   c\n0  21  72  67\n1  23  78  69\n2  32  74  56\n3  52  54  76\n\nNumpy Array\n----------\n [[21 72 67]\n [23 78 69]\n [32 74 56]\n [52 54 76]]\n(4, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "\t[[21, 72, 67],\n",
    "\t[23, 78, 69],\n",
    "\t[32, 74, 56],\n",
    "\t[52, 54, 76]],\n",
    "\tcolumns=['a', 'b', 'c'])\n",
    "\n",
    "print('DataFrame\\n----------\\n', df)\n",
    "\n",
    "#convert dataframe to numpy array\n",
    "arr = df.to_numpy()\n",
    "\n",
    "print('\\nNumpy Array\\n----------\\n', arr)\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              a             b             c\n",
       "0  [21, 21, 21]  [72, 72, 72]  [67, 67, 67]\n",
       "1  [23, 23, 23]  [78, 78, 78]  [69, 69, 69]\n",
       "2  [32, 32, 32]  [74, 74, 74]  [56, 56, 56]\n",
       "3  [52, 52, 52]  [54, 54, 54]  [76, 76, 76]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[21, 21, 21]</td>\n      <td>[72, 72, 72]</td>\n      <td>[67, 67, 67]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[23, 23, 23]</td>\n      <td>[78, 78, 78]</td>\n      <td>[69, 69, 69]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[32, 32, 32]</td>\n      <td>[74, 74, 74]</td>\n      <td>[56, 56, 56]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[52, 52, 52]</td>\n      <td>[54, 54, 54]</td>\n      <td>[76, 76, 76]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "df.applymap(lambda x: [x,x,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    a   b   c\n",
       "0  21  72  67\n",
       "1  23  78  69\n",
       "2  32  74  56\n",
       "3  52  54  76"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>72</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23</td>\n      <td>78</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>74</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>54</td>\n      <td>76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 2 3]\n [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3], [4,5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-42b16fc2d200>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-42b16fc2d200>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    duplicater = lambda t: [x,x,x] for x in t\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "duplicater = lambda t: [x,x,x]\n",
    "func = np.vectorize(duplicater)\n",
    "func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "       [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.repeat(x,21) \n",
    "np.apply_along_axis(f,1,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "62//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "np.argmax([[5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}